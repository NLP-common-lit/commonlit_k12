{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "url_legal         2004\n",
       "license           2004\n",
       "excerpt              0\n",
       "target               0\n",
       "standard_error       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2834, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "https://www.africanstorybook.org/                                                                                          118\n",
       "https://www.africanstorybook.org/#                                                                                          46\n",
       "https://simple.wikipedia.org/wiki/Voltage                                                                                    2\n",
       "https://en.wikipedia.org/wiki/Open-source_software                                                                           1\n",
       "https://simple.wikipedia.org/wiki/Blu-ray_Disc                                                                               1\n",
       "                                                                                                                          ... \n",
       "https://freekidsbooks.org/wp-content/uploads/2019/10/Freekidsbooks-Area-Apprenticeship-and-Workplace-Mathematics-10.pdf      1\n",
       "https://en.wikipedia.org/wiki/Electrostatic_generator                                                                        1\n",
       "https://kids.frontiersin.org/article/10.3389/frym.2016.00020                                                                 1\n",
       "https://www.commonlit.org/texts/duke-ellington                                                                               1\n",
       "https://en.wikipedia.org/wiki/Cabinet_(government)                                                                           1\n",
       "Name: url_legal, Length: 667, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.url_legal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- set id as the index\n",
    "- should remove url_legal andlicense\n",
    "- do a basic clean on excerpt\n",
    "    - remove accented characters\n",
    "    - remove special characters\n",
    "    - tokenization\n",
    "    - lemmatization\n",
    "    - remove stopwords\n",
    "- late on web scrape from https://www.africanstorybook.org/   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set id as index\n",
    "df.set_index('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          url_legal license  \\\n",
       "id                            \n",
       "c12129c31       NaN     NaN   \n",
       "\n",
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "\n",
       "           standard_error  \n",
       "id                         \n",
       "c12129c31        0.464009  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop url_legal and license columns\n",
    "df.drop(columns=['url_legal', 'license'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "\n",
       "           standard_error  \n",
       "id                         \n",
       "c12129c31        0.464009  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    '''Takes in string\n",
    "    makes everything lowercase\n",
    "    removes incosistent text\n",
    "    only keeps anything a-z, 0-9, ' and white space'''\n",
    "    # make everything lowercase\n",
    "    string = string.lower()\n",
    "    # removes incosistencies in the text\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "    # set what to keep\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    # return new cleaned string\n",
    "    return string\n",
    "\n",
    "df['cleaned_excerpt'] = df.excerpt.apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>cleaned_excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "\n",
       "           standard_error                                    cleaned_excerpt  \n",
       "id                                                                            \n",
       "c12129c31        0.464009  when the young people returned to the ballroom...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    '''Takes in the string provided by basic_clean funciton\n",
    "    creates a tokenizer\n",
    "    uses the tokenizerr on the cleaned string'''\n",
    "    # Create the tokenizer\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    # Use the tokenizer\n",
    "    string = tokenizer.tokenize(string, return_str = True)\n",
    "    # return tokenized string\n",
    "    return string\n",
    "\n",
    "df['tokenized_excerpt'] = df.excerpt.apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>cleaned_excerpt</th>\n",
       "      <th>tokenized_excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "\n",
       "           standard_error                                    cleaned_excerpt  \\\n",
       "id                                                                             \n",
       "c12129c31        0.464009  when the young people returned to the ballroom...   \n",
       "\n",
       "                                           tokenized_excerpt  \n",
       "id                                                            \n",
       "c12129c31  when the young people returned to the ballroom...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    '''In string from the basic_clean and tokenize fucntion\n",
    "    creaters the porter stemmer\n",
    "    applies the porter stemmer to every word in the string provided\n",
    "    joing the list of words back into a string'''\n",
    "    # Create porter stemmer.\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    # Apply the stemmer to each word in our string\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    # Join the list of words into the string\n",
    "    string_stemmed = ' '.join(stems)\n",
    "    # return string_stemmed\n",
    "    return string_stemmed\n",
    "\n",
    "df['stemmed_excerpt'] = df.tokenized_excerpt.apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>cleaned_excerpt</th>\n",
       "      <th>tokenized_excerpt</th>\n",
       "      <th>stemmed_excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "      <td>when the young peopl return to the ballroom it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "\n",
       "           standard_error                                    cleaned_excerpt  \\\n",
       "id                                                                             \n",
       "c12129c31        0.464009  when the young people returned to the ballroom...   \n",
       "\n",
       "                                           tokenized_excerpt  \\\n",
       "id                                                             \n",
       "c12129c31  when the young people returned to the ballroom...   \n",
       "\n",
       "                                             stemmed_excerpt  \n",
       "id                                                            \n",
       "c12129c31  when the young peopl return to the ballroom it...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    '''Takes in string from basic_clean and tokenize funcitons\n",
    "    creates a lematizer\n",
    "    uses the lematizer on each word in the string\n",
    "    merges the list of words back into string format\n",
    "    and returns the now lematized string'''\n",
    "    # Create the Lemmatizer.\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    # Use the lemmatizer on each word using split\n",
    "    lemmas = [wnl.lemmatize(word) for word in string.split()]\n",
    "    # Join the list into a string\n",
    "    string_lemmatized = ' '.join(lemmas)\n",
    "    # return lemmatized string\n",
    "    return string_lemmatized\n",
    "\n",
    "df['lemma_excerpt'] = df.tokenized_excerpt.apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>cleaned_excerpt</th>\n",
       "      <th>tokenized_excerpt</th>\n",
       "      <th>stemmed_excerpt</th>\n",
       "      <th>lemma_excerpt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c12129c31</th>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "      <td>when the young people returned to the ballroom...</td>\n",
       "      <td>when the young peopl return to the ballroom it...</td>\n",
       "      <td>when the young peopl return to the ballroom it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     excerpt    target  \\\n",
       "id                                                                       \n",
       "c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "\n",
       "           standard_error                                    cleaned_excerpt  \\\n",
       "id                                                                             \n",
       "c12129c31        0.464009  when the young people returned to the ballroom...   \n",
       "\n",
       "                                           tokenized_excerpt  \\\n",
       "id                                                             \n",
       "c12129c31  when the young people returned to the ballroom...   \n",
       "\n",
       "                                             stemmed_excerpt  \\\n",
       "id                                                             \n",
       "c12129c31  when the young peopl return to the ballroom it...   \n",
       "\n",
       "                                               lemma_excerpt  \n",
       "id                                                            \n",
       "c12129c31  when the young peopl return to the ballroom it...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, exclude_words=[], extra_words=[]):\n",
    "    '''takes in string from basic clean and tokenize fucntions\n",
    "    takes in a list of words to exclude from the stopword list\n",
    "    take sin a list of words to include in the stopword list\n",
    "    makes the list of stopwords\n",
    "    removes words listed from stopword list\n",
    "    add words listed to stopword list\n",
    "    remove words from stopword list from the string\n",
    "    join words back to string format\n",
    "    return new string'''\n",
    "    # set stopword list \n",
    "    stopword_list = stopwords.words('english')\n",
    "    # remove exclude_words list from stopword list\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    # add extra_wrods list to stopword list\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    # remove stopword list words from string\n",
    "    string = string.split()\n",
    "    # set filtered words value\n",
    "    filtered_words = [word for word in string if word not in stopword_list]\n",
    "    # join words back into string format \n",
    "    string = ' '.join(filtered_words)\n",
    "    # return new string\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/caitlyncarney/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'young people returned ballroom presented decidedly changed appearance instead interior scene winter landscape floor covered snowwhite canvas laid smoothly rumpled bumps hillocks like real snow field numerous palms evergreens decorated room powdered flour strewn tufts cotton like snow also diamond dust lightly sprinkled glittering crystal icicles hung branches end room wall hung beautiful bearskin rug rugs prizes one girls one boys game girls gathered one end room boys one end called north pole south pole player given small flag plant reaching pole would easy matter traveller obliged wear snowshoes'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = df.tokenized_excerpt.iloc[0]\n",
    "remove_stopwords(document, extra_words=['who', 'and'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words=['who', 'and']\n",
    "df['no_stopwords_stem'] = df.stemmed_excerpt.apply(remove_stopwords, extra_words=extra_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words=['who', 'and']\n",
    "df['no_stopwords_lemma'] = df.lemma_excerpt.apply(remove_stopwords, extra_words=extra_words)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
